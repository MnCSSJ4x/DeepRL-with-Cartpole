{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ba537d40989a43d09bd956d7095f7a96":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed9de1b414b6427b93c416f35c67de03","IPY_MODEL_6185eb41e3ae407497601b018adb659e","IPY_MODEL_59729f169c7b4a358d9a1ea21eb37bfb"],"layout":"IPY_MODEL_32b18ae3d17b4d25a1c2ec01258cd775"}},"ed9de1b414b6427b93c416f35c67de03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_937aac942dd9420a91323e5c26de2a52","placeholder":"​","style":"IPY_MODEL_8578e31579384559bf3e5cfbdd4f1b5e","value":" 11%"}},"6185eb41e3ae407497601b018adb659e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f85ff152c091460bb9e362d2e4d017cd","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2f66e7d8b964095b467b23d16c7c641","value":57}},"59729f169c7b4a358d9a1ea21eb37bfb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a24d19c9e2b74baa9288945086ec9b72","placeholder":"​","style":"IPY_MODEL_cca13aa78aeb46baa2e32cb5c6952c71","value":" 57/500 [06:23&lt;1:56:05, 15.72s/it]"}},"32b18ae3d17b4d25a1c2ec01258cd775":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"937aac942dd9420a91323e5c26de2a52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8578e31579384559bf3e5cfbdd4f1b5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f85ff152c091460bb9e362d2e4d017cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2f66e7d8b964095b467b23d16c7c641":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a24d19c9e2b74baa9288945086ec9b72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cca13aa78aeb46baa2e32cb5c6952c71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gymnasium\n# !pip install torchviz\n!pip install pygame","metadata":{"id":"GsgMG6fNM_Ku","outputId":"33a8901d-0f4c-41d4-87ac-1e0d1dd36959","execution":{"iopub.status.busy":"2024-03-26T19:31:48.200702Z","iopub.execute_input":"2024-03-26T19:31:48.201069Z","iopub.status.idle":"2024-03-26T19:32:15.052374Z","shell.execute_reply.started":"2024-03-26T19:31:48.201040Z","shell.execute_reply":"2024-03-26T19:32:15.051186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %matplotlib inline\n# %load_ext tensorboard\n# %tensorboard --logdir logs","metadata":{"id":"tKRqnPNDNDGE","outputId":"c94ff9cb-649c-4e0b-dd86-2e58d5e4042e","execution":{"iopub.status.busy":"2024-03-26T19:32:15.055204Z","iopub.execute_input":"2024-03-26T19:32:15.055608Z","iopub.status.idle":"2024-03-26T19:32:15.059945Z","shell.execute_reply.started":"2024-03-26T19:32:15.055571Z","shell.execute_reply":"2024-03-26T19:32:15.058959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import count\nimport random\nimport gymnasium as gym\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom tqdm.notebook import tqdm\nfrom torch.utils.tensorboard import SummaryWriter\nimport math\nfrom collections import deque, namedtuple\nimport random\nfrom torchvision.models import resnet18\nimport numpy as np","metadata":{"id":"XMRk02swNI4m","execution":{"iopub.status.busy":"2024-03-26T19:32:15.061210Z","iopub.execute_input":"2024-03-26T19:32:15.061533Z","iopub.status.idle":"2024-03-26T19:32:33.732040Z","shell.execute_reply.started":"2024-03-26T19:32:15.061505Z","shell.execute_reply":"2024-03-26T19:32:33.731057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def render_environment(env):\n    plt.figure(figsize=(6, 4))\n    plt.imshow(env.render())\n    plt.axis('off')\n    plt.show()","metadata":{"id":"oMybM1EvNJmm","execution":{"iopub.status.busy":"2024-03-26T19:32:33.733413Z","iopub.execute_input":"2024-03-26T19:32:33.734102Z","iopub.status.idle":"2024-03-26T19:32:33.739422Z","shell.execute_reply.started":"2024-03-26T19:32:33.734068Z","shell.execute_reply":"2024-03-26T19:32:33.738387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env = gym.make(\"CartPole-v1\",render_mode=\"rgb_array\")\nwriter = SummaryWriter(\"logs\")\ndevice = torch.device(\n    \"mps\"\n    if torch.backends.mps.is_available()\n    else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n)\nis_ipython = 'inline' in matplotlib.get_backend()\nif is_ipython:\n    from IPython import display\n\nplt.ion()","metadata":{"id":"aWwgqGkxNLec","outputId":"2399ddc0-9901-4583-826f-1484d4f4c786","execution":{"iopub.status.busy":"2024-03-26T19:32:33.742804Z","iopub.execute_input":"2024-03-26T19:32:33.743163Z","iopub.status.idle":"2024-03-26T19:32:33.909693Z","shell.execute_reply.started":"2024-03-26T19:32:33.743132Z","shell.execute_reply":"2024-03-26T19:32:33.908816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HYPER-PARAMETERS\n# BATCH_SIZE is the number of transitions sampled from the replay buffer\n# GAMMA is the discount factor as mentioned in the previous section\n# EPS_START is the starting value of epsilon\n# EPS_END is the final value of epsilon\n# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n# TAU is the update rate of the target network\n# LR is the learning rate of the ``AdamW`` optimizer\n\nBATCH_SIZE = 512\nGAMMA = 0.4\nEPS_START = 0.9\nEPS_END = 0.05\nEPS_DECAY = 1000\nTAU = 0.005\nLR = 1e-4\nREPLAY_BUFFER_SIZE = 10000","metadata":{"id":"K56j-MW9NN8-","execution":{"iopub.status.busy":"2024-03-26T19:32:33.910814Z","iopub.execute_input":"2024-03-26T19:32:33.911172Z","iopub.status.idle":"2024-03-26T19:32:33.916078Z","shell.execute_reply.started":"2024-03-26T19:32:33.911141Z","shell.execute_reply":"2024-03-26T19:32:33.915229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Transition = namedtuple(\"Transition\", (\"state\", \"action\", \"next_state\", \"reward\"))\nclass ReplayBuffer(object):\n    def __init__(self, capacity):\n        self.memory = deque([], maxlen=capacity)\n\n    def push(self, *args):\n        \"\"\"Save a transition\"\"\"\n        self.memory.append(Transition(*args))\n\n    def sample(self, batch_size):\n        return random.sample(self.memory, batch_size)\n\n    def __len__(self):\n        return len(self.memory)","metadata":{"id":"U7dhHaTkNP5L","execution":{"iopub.status.busy":"2024-03-26T19:32:33.917423Z","iopub.execute_input":"2024-03-26T19:32:33.917808Z","iopub.status.idle":"2024-03-26T19:32:33.927063Z","shell.execute_reply.started":"2024-03-26T19:32:33.917776Z","shell.execute_reply":"2024-03-26T19:32:33.926267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resnet_model = resnet18(pretrained=True)","metadata":{"id":"jTZ2MCvy8Gls","outputId":"2b3c57a1-fd52-4e17-9f75-dd32fd883cae","execution":{"iopub.status.busy":"2024-03-26T19:32:33.928084Z","iopub.execute_input":"2024-03-26T19:32:33.928414Z","iopub.status.idle":"2024-03-26T19:32:33.940452Z","shell.execute_reply.started":"2024-03-26T19:32:33.928375Z","shell.execute_reply":"2024-03-26T19:32:33.939678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class ResNetFeatureExtractor(nn.Module):\n#     def __init__(self):\n#         super(ResNetFeatureExtractor, self).__init__()\n#         self.features = nn.Sequential(*list(resnet_model.children())[:-1])\n#         for param in self.features.parameters():\n#             param.requires_grad = False\n#     def forward(self, x):\n#         x = self.features(x)\n#         return x","metadata":{"id":"9V3Mu3Xo8tcZ","execution":{"iopub.status.busy":"2024-03-26T19:32:33.943220Z","iopub.execute_input":"2024-03-26T19:32:33.943557Z","iopub.status.idle":"2024-03-26T19:32:33.950902Z","shell.execute_reply.started":"2024-03-26T19:32:33.943532Z","shell.execute_reply":"2024-03-26T19:32:33.950026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DQN(nn.Module):\n    def __init__(self, n_observations,n_actions):\n        super(DQN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        \n        self.bn1 = nn.BatchNorm2d(16)\n        self.bn2 = nn.BatchNorm2d(32)\n        self.bn3 = nn.BatchNorm2d(64)\n        \n        # Define ReLU activation function\n        self.relu = nn.ReLU(inplace=True)\n        \n        # Define adaptive average pooling\n        self.avgpool = nn.AdaptiveAvgPool2d((4,4))\n        self.layer1 = nn.Linear(1024, 128)\n        self.layer2 = nn.Linear(128, 64)\n        self.layer3 = nn.Linear(64, n_actions)\n\n    def forward(self, x):\n        x = self.conv1(x.to(device))\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        \n        x = self.conv3(x)\n        x = self.bn3(x)\n        x = self.relu(x)\n        \n        # Adaptive average pooling\n        x = self.avgpool(x)\n        x = F.relu(self.layer1(x.flatten(1)))\n        x = F.relu(self.layer2(x))\n        return self.layer3(x)","metadata":{"id":"dUbNl5CpNR7h","execution":{"iopub.status.busy":"2024-03-26T19:32:33.952146Z","iopub.execute_input":"2024-03-26T19:32:33.952781Z","iopub.status.idle":"2024-03-26T19:32:33.964945Z","shell.execute_reply.started":"2024-03-26T19:32:33.952740Z","shell.execute_reply":"2024-03-26T19:32:33.964069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_actions = env.action_space.n\nstate, info = env.reset(seed=42)\nn_observations = len(state)\nrender_environment(env)","metadata":{"id":"uMPCIu49k9hp","outputId":"6bb34d16-2425-4e14-8cc4-e1d43cbaf0e7","execution":{"iopub.status.busy":"2024-03-26T19:32:33.965954Z","iopub.execute_input":"2024-03-26T19:32:33.966206Z","iopub.status.idle":"2024-03-26T19:32:34.463174Z","shell.execute_reply.started":"2024-03-26T19:32:33.966185Z","shell.execute_reply":"2024-03-26T19:32:34.461898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocess = transforms.Compose([\n  transforms.ToPILImage(),\n  transforms.CenterCrop(448), \n  transforms.Resize((224, 224)),\n  transforms.ToTensor(),\n])","metadata":{"id":"IbIFucXE98JB","execution":{"iopub.status.busy":"2024-03-26T19:32:34.465342Z","iopub.execute_input":"2024-03-26T19:32:34.466276Z","iopub.status.idle":"2024-03-26T19:32:34.473588Z","shell.execute_reply.started":"2024-03-26T19:32:34.466225Z","shell.execute_reply":"2024-03-26T19:32:34.472375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_action(state,policy_net):\n    global steps_done\n    sample = random.random()\n    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(\n        -1.0 * steps_done / EPS_DECAY\n    )\n    steps_done += 1\n    if sample > eps_threshold:\n        with torch.no_grad():\n            # t.max(1) will return the largest column value of each row.\n            # second column on max result is index of where max element was\n            # found, so we pick action with the larger expected reward.\n            return policy_net(state).max(1).indices.view(1, 1)\n    else:\n        return torch.tensor(\n            [[env.action_space.sample()]], device=device, dtype=torch.long\n        )","metadata":{"id":"xKTGHK5Zh79z","execution":{"iopub.status.busy":"2024-03-26T19:32:34.475664Z","iopub.execute_input":"2024-03-26T19:32:34.476569Z","iopub.status.idle":"2024-03-26T19:32:34.488525Z","shell.execute_reply.started":"2024-03-26T19:32:34.476522Z","shell.execute_reply":"2024-03-26T19:32:34.487193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_done = 0","metadata":{"id":"NWUQMDAemDzH","execution":{"iopub.status.busy":"2024-03-26T19:32:34.494981Z","iopub.execute_input":"2024-03-26T19:32:34.496185Z","iopub.status.idle":"2024-03-26T19:32:34.503433Z","shell.execute_reply.started":"2024-03-26T19:32:34.496137Z","shell.execute_reply":"2024-03-26T19:32:34.502154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def single_run(BATCH_SIZE, GAMMA, EPS_START, EPS_END, EPS_DECAY, TAU, LR,REPLAY_BUFFER_SIZE,EXP_NAME):\n  writer = SummaryWriter(f'logs/{EXP_NAME}/CNN_BASED/RESNET/BATCH_SIZE-{BATCH_SIZE}-GAMMA-{GAMMA}-EPS_START-{EPS_START}-EPS_END-{EPS_END}-EPS_DECAY-{EPS_DECAY}-TAU-{TAU}-LR-{LR}-REPLAY_BUFFEER_SIZE-{REPLAY_BUFFER_SIZE}')\n  policy_net = DQN(n_observations, n_actions).to(device)\n  target_net = DQN(n_observations, n_actions).to(device)\n  target_net.load_state_dict(policy_net.state_dict())\n  memory = ReplayBuffer(REPLAY_BUFFER_SIZE)\n  optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n  steps_done = 0\n  episode_durations = []\n  episode_rewards = []\n  epoch_q_values = []\n  if torch.cuda.is_available() or torch.backends.mps.is_available():\n      num_episodes = 500\n  else:\n      num_episodes = 50\n\n  for i_episode in tqdm(range(num_episodes)):\n      torch.cuda.empty_cache()\n      # Initialize the environment and get its state\n      state, info = env.reset()\n      image = env.render()\n      image = preprocess(image)\n      # print(image.shape)\n      state = torch.tensor(image, dtype=torch.float32, device=device).unsqueeze(0)\n      # print(state.shape)\n      episode_reward = 0\n      epoch_q_value = 0\n      \n      for t in count():\n          action = select_action(state,policy_net)\n          observation, reward, terminated, truncated, _ = env.step(action.item())\n          reward = torch.tensor([reward], device=device)\n          episode_reward+=reward.item()\n\n          q_values = policy_net(state)\n          q_value = q_values[0, action].item()\n          epoch_q_value += q_value\n\n\n          done = terminated or truncated\n\n          if terminated:\n              next_state = None\n          else:\n              image = env.render()\n              image = preprocess(image)\n              next_state = torch.tensor(image, dtype=torch.float32, device=device).unsqueeze(0)\n\n          memory.push(state.detach().cpu(), action.detach().cpu(), next_state.detach().cpu() if next_state is not None else None, reward.detach().cpu())\n          state = next_state\n\n          # Perform one step of the optimization (on the policy network)\n          if len(memory) >= BATCH_SIZE:\n            transitions = memory.sample(BATCH_SIZE)\n            batch = Transition(*zip(*transitions))\n            non_final_mask = torch.tensor(\n                tuple(map(lambda s: s is not None, batch.next_state)),\n                device=device,\n                dtype=torch.bool,\n            )\n            non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n            state_batch = torch.cat(batch.state).to(device)\n            action_batch = torch.cat(batch.action).to(device)\n            reward_batch = torch.cat(batch.reward).to(device)\n            state_action_values = policy_net(state_batch).gather(1, action_batch)\n            next_state_values = torch.zeros(BATCH_SIZE, device=device)\n            with torch.no_grad():\n                next_state_values[non_final_mask] = (\n                    target_net(non_final_next_states).max(1).values\n                )\n            expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n            criterion = nn.SmoothL1Loss()\n            loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n            writer.add_scalar(\"Loss\", loss.item(), i_episode)\n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n            optimizer.step()\n\n          target_net_state_dict = target_net.state_dict()\n          policy_net_state_dict = policy_net.state_dict()\n          for key in policy_net_state_dict:\n              target_net_state_dict[key] = policy_net_state_dict[key] * TAU + target_net_state_dict[key] * (1 - TAU)\n          target_net.load_state_dict(target_net_state_dict)\n          if done:\n              writer.add_scalar(\"Average Reward\",episode_reward,i_episode)\n              average_q_value = epoch_q_value / (t + 1)\n              epoch_q_values.append(average_q_value)\n              writer.add_scalar(\"Average Q-value\", average_q_value, i_episode)\n              episode_durations.append(t + 1)\n              break\n  writer.add_hparams({'LR': LR, 'BATCH_SIZE': BATCH_SIZE, 'GAMMA':GAMMA,'EPS_START':EPS_START,'EPS_END':EPS_END,'TAU':TAU,'REPLAY_BUFFER_SIZE':REPLAY_BUFFER_SIZE}, {'hparam/loss': loss.item(), 'hparam/reward': reward,'average_q_value':average_q_value})\n  torch.save(policy_net.state_dict(), 'dqn_cnn_model.pth')","metadata":{"id":"ZZYD58T5-CjZ","execution":{"iopub.status.busy":"2024-03-26T19:32:34.505834Z","iopub.execute_input":"2024-03-26T19:32:34.506641Z","iopub.status.idle":"2024-03-26T19:32:34.534695Z","shell.execute_reply.started":"2024-03-26T19:32:34.506593Z","shell.execute_reply":"2024-03-26T19:32:34.533743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"hA6xvbYT-L4s","execution":{"iopub.status.busy":"2024-03-26T19:32:34.535770Z","iopub.execute_input":"2024-03-26T19:32:34.536031Z","iopub.status.idle":"2024-03-26T19:32:34.548436Z","shell.execute_reply.started":"2024-03-26T19:32:34.536009Z","shell.execute_reply":"2024-03-26T19:32:34.547644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"REPLAY_BUFFER_SIZE = 100000\nBATCH_SIZE = 128\nGAMMA = 0.4\nEPS_START = 0.9\nEPS_END = 0.05\nEPS_DECAY = 1000\nTAU = 0.005\nLR = 1e-4\nsingle_run(BATCH_SIZE, GAMMA, EPS_START, EPS_END, EPS_DECAY, TAU, LR,REPLAY_BUFFER_SIZE,'REPLAY_BUFFER')","metadata":{"id":"UXSQDO3-kiLh","outputId":"113fa012-8bca-4b2a-e3d2-b457df895f73","execution":{"iopub.status.busy":"2024-03-26T19:32:40.571220Z","iopub.execute_input":"2024-03-26T19:32:40.572095Z","iopub.status.idle":"2024-03-26T19:37:39.472574Z","shell.execute_reply.started":"2024-03-26T19:32:40.572064Z","shell.execute_reply":"2024-03-26T19:37:39.471150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorboard import notebook\n# notebook.list()\n# notebook.display(port=6006, height=500)","metadata":{"id":"xw9ve4_2pafw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# policy_net = DQN(n_observations, n_actions).to(device)\n# policy_net.load_state_dict(torch.load('dqn_cnn_model.pth'))\n# policy_net.eval() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install imageio\n# import imageio\n# from IPython.display import Video","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# state,_ = env.reset()\n# image = env.render()\n# image = preprocess(image)\n# state = torch.tensor(image, dtype=torch.float32, device=device).unsqueeze(0)\n\n# done = False\n# frames = []\n# while not done:\n#   frames.append(env.render())\n#   with torch.no_grad():\n#         image = env.render()\n#         image = preprocess(image)\n#         state = torch.tensor(image, dtype=torch.float32, device=device).unsqueeze(0)\n#         action = policy_net(state).argmax(dim=1).item()\n#   state, reward, terminated, truncated,_ = env.step(action)\n#   done = terminated or truncated\n# imageio.mimsave('output.mp4', frames)\n# env.close()\n\n# Video(\"output.mp4\", embed=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}